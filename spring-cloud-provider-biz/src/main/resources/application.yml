server:
  port: 9010
spring:
  application:
    name: biz-provider

  cloud:
    #    配置consul地址,用来将自身服务注册到consul上
    consul:
      host: 127.0.0.1
      port: 8500

#       consul服务发现配置
      discovery:
        enabled: true #启用服务发现
        register: true #启用服务注册
        deregister: true #服务停止时取消注册
        prefer-ip-address: true #表示注册时使用IP而不是HostName
        health-check-interval: 10s  #健康检查频率
        health-check-critical-timeout: 30s



#      consul配置中心配置(可在consul控制台修改key-value对来影响程序对应属性)
      config:
        enabled: true
        format: YAML    # 表示consul上面文件的格式 有四种 YAML PROPERTIES KEY-VALUE FILES
        data-key: data    #表示consul上面的KEY值(或者说文件的名字) 默认是data
#        prefix:       #设置配置值的基本文件夹
#        defaultContext:    #设置所有应用程序使用的文件夹名称
#        profileSeparator:         #设置用于使用配置文件在属性源中分隔配置文件名称的分隔符的值

#    sentinel配置(熔断/限流)
    sentinel:
      enabled: true
      transport:
#        被sentinel监听的服务的端口(server.port + 1)
        port: 9011
#        Sentinel 控制台地址（Sentinel控制台需要单独安装,控制台登录需要密码(默认用户名和密码都是 sentinel),下载地址:https://github.com/alibaba/Sentinel/releases）
        dashboard: localhost:8080
#      取消Sentinel控制台懒加载
      eager: true

    stream:
      kafka:
#        Binder 是 Spring Cloud Stream 的一个抽象概念，是应用与消息中间件之间的粘合剂。目前 Spring Cloud Stream 实现了 Kafka 和 Rabbit MQ 的binder
        binder:
          auto-create-topics: true
#          brokers: localhost:9092
          brokers: 192.168.1.142:9092
          replication-factor: 1
#      bindings 是我们通过配置把应用和spring cloud stream 的 binder 绑定在一起，之后我们只需要修改 binding 的配置来达到动态修改topic、exchange、type等一系列信息而不需要修改一行代码
      bindings:
#        自定义通道名
        datasourceOutPut:
#          消息发往的目的地(也就是输入通道对应的主题名)
          destination: datasourceInPut
#          消息发送的格式，接收端不用指定格式，但是发送端要
          content-type: text/plain
        datasourceInPut:
#          消息发往的目的地(也就是输入通道对应的主题名)
          destination: datasourceInPut
#          消息发送的格式，接收端不用指定格式，但是发送端要
          content-type: text/plain




#  链路追踪配置
  sleuth:
    enabled: true
#    设置不通过http传输
    http:
      enabled: true
    feign:
      enabled: true
    messaging:
      kafka:
        enabled: true
    sampler:
#      收集追踪信息的比率，如果是0.1则表示只记录10%的追踪数据，如果要全部追踪，设置为1（实际场景不推荐，因为会造成不小的性能消耗）
      probability: 1.0
#    使用128位的traceId代替64位的traceId
    trace-id128: true

  zipkin:
    enabled: true
#    sender:
#     当设置了zipkin传输方式为消息中间件时,那么在启动zipkin server端需要加上启动参数,如: java -DKAFKA_ZOOKEEPER=192.168.1.142:2181 -jar zipkin.jar
#      type: kafka
#    是否启用服务发现,如果为false ,则以base-url设置为准
    discovery-client-enabled: true
#   当设置sleuth-cli收集信息后通过http传输到zinkin-server时,zipkin服务端地址
    base-url: http://localhost:9411/
#    在发送给zipkin server之前是否进行压缩数据
    compression:
      enabled: true





feign:
  compression:
    request:
      min-request-size: 2048
      mime-types:
        - "text/xml"
        - "application/xml"
        - "application/json"
      enabled: true
  okhttp:
    #    是否开启okhttp (使用httpclient/okhttp都是为了优化feign,因为feign默认是http连接的,且没有连接池,因此需要替换实现)
    enabled: true
  httpclient:
    #    是否开启httpclient
    enabled: false




kanyun:
  datasource:
    dynamic:
      enabled: true


#Spring Boot2.x中(也即：spring-boot-starter-actuator)，默认只开放了info、health两个端点，开放其他端点需要配置
management:
  endpoints:
    web:
      exposure:
#        开启所有端点:
        include: "*"
#    启用所有端口
    enabled-by-default: true
  endpoint:
    shutdown:
#      打开 shutdown 端点，通过 POST 访问该端点可以关闭应用
      enabled: true
    health:
#      显示详细的 health 信息
      show-details: always